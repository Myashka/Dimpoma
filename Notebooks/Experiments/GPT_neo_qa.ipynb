{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc5a668",
   "metadata": {},
   "source": [
    "# Общая информация\n",
    "__Цель:__ сделать fine-tuning mGPT by Sber\n",
    "\n",
    "__Задачи:__\n",
    "1) Выбрать вопросы с определенным тегом, например python\n",
    "\n",
    "2) Понять формат входных и выходных данных, например перед вопросов, возможно надо ставить [QUESTION]\n",
    "\n",
    "3) Сделать torch Dataset\n",
    "\n",
    "4) Определить, как делать evaluation\n",
    "\n",
    "5) Способ трэкинга\n",
    "\n",
    "6) Проанализировать результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf5036",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f0cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import load_metric\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          IntervalStrategy, Trainer, TrainingArguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa2d2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18f046ac9f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# зафиксируем random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1fe0d",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79da9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "with open(f\"../../data/filtered_df.p\", \"rb\") as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d30bef",
   "metadata": {},
   "source": [
    "Отсортируем датасет по времени и разобьем его на train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fad6cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"Q_Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f0d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.apply(lambda x: f\"python\" in x.Tag, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61090fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = np.split(df, [int(0.75 * len(df))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88795940",
   "metadata": {},
   "source": [
    "# Загрузим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6215b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31a55a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name,\n",
    "    bos_token=\"<|startoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    pad_token=\"<|pad|>\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "925bde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ed943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3911c6fc",
   "metadata": {},
   "source": [
    "Отберем только те строки, в тегах которых есть слово _python_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5156e7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1055\n"
     ]
    }
   ],
   "source": [
    "questions = df.Q_Body\n",
    "max_length = max([len(tokenizer.encode(question)) for question in questions])\n",
    "print(f\"Max length: {max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb78b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_A_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, tag):\n",
    "        df = df.loc[df.apply(lambda x: f\"{tag}\" in x.Tag, axis=1)]\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.answers = []\n",
    "        self.questions = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            prep_text = f\"<|startoftext|>Question: {row.Q_Body}\\nAnswer: {row.A_Body}<|endoftext|>\"\n",
    "\n",
    "            question_len = len(\n",
    "                tokenizer(\n",
    "                    f\"<|startoftext|>Question: {row.Q_Body}\\nAnswer:\",\n",
    "                )[\"input_ids\"]\n",
    "            )\n",
    "\n",
    "            encoding_dict = tokenizer(\n",
    "                prep_text, truncation=True, max_length=max_length, padding=\"max_length\"\n",
    "            )\n",
    "\n",
    "            self.input_ids.append(torch.tensor(encoding_dict[\"input_ids\"]))\n",
    "            self.attn_masks.append(torch.tensor(encoding_dict[\"attention_mask\"]))\n",
    "            self.labels.append(torch.tensor(encoding_dict[\"input_ids\"]))\n",
    "            self.labels[-1][:question_len] = -100\n",
    "\n",
    "            self.answers.append(row.A_Body)\n",
    "            self.questions.append(row.Q_Body)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.input_ids[idx],\n",
    "            self.attn_masks[idx],\n",
    "            self.labels[idx],\n",
    "            self.answers[idx],\n",
    "            self.questions[idx],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8022f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Q_A_Dataset(train_df, tokenizer, max_length=max_length, tag=\"python\")\n",
    "test_dataset = Q_A_Dataset(test_df, tokenizer, max_length=max_length, tag=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "852d170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cdfcd",
   "metadata": {},
   "source": [
    "# Определим evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1db983",
   "metadata": {},
   "source": [
    "Определить метрики качества \\ __BLEU, ROGUE__\n",
    "\n",
    "Трекинг модели в wandb\n",
    "\n",
    "API HF Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1004533",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = load_metric(\"bleu\")\n",
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cfd9f",
   "metadata": {},
   "source": [
    "# Авторизумеся в wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1d7196a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\porsh/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2a2411e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmyashka\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\vkr\\Notebooks\\Experiments\\wandb\\run-20220927_160745-39g7abts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/myashka/QA%20specific%20domain/runs/39g7abts\" target=\"_blank\">earthy-dust-1</a></strong> to <a href=\"https://wandb.ai/myashka/QA%20specific%20domain\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/myashka/QA%20specific%20domain/runs/39g7abts?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x18f91d451e0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"QA specific domain\", entity=\"myashka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a0f1e532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_LOG_MODEL=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5bc0fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_WATCH=all\n",
      "env: WANDB_SILENT=true\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_WATCH=all\n",
    "%env WANDB_SILENT=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3611f270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">earthy-dust-1</strong>: <a href=\"https://wandb.ai/myashka/QA%20specific%20domain/runs/39g7abts\" target=\"_blank\">https://wandb.ai/myashka/QA%20specific%20domain/runs/39g7abts</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220927_160745-39g7abts\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5a327",
   "metadata": {},
   "source": [
    "# Определим Trainer и запустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49ea6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = lambda data: {\n",
    "    \"input_ids\": torch.stack([f for f in data[0]]),\n",
    "    \"attention_mask\": torch.stack([f for f in data[1]]),\n",
    "    \"labels\": torch.stack([f for f in data[2]]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f86eb745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1055])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(train_dataset[0:2])[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80817459",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"wandb\",  # enable logging to W&B\n",
    "    run_name=\"gpt_neo_first_run\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=lambda data: {\n",
    "        \"input_ids\": torch.stack([f for f in data[0]]),\n",
    "        \"attention_mask\": torch.stack([f for f in data[1]]),\n",
    "        \"labels\": torch.stack([f for f in data[2]]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d1e4e7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[[50257, 24361,    25,  ..., 50258, 50258, 50258]],\n",
       " \n",
       "         [[50257, 24361,    25,  ..., 50258, 50258, 50258]]]),\n",
       " 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0]]]),\n",
       " 'labels': tensor([[[-100, -100, -100,  ..., -100, -100, -100]],\n",
       " \n",
       "         [[-100, -100, -100,  ..., -100, -100, -100]]])}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(train_dataset[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f308c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd0c2d",
   "metadata": {},
   "source": [
    "### #TODO\n",
    "1. Дописать evaluate\n",
    "2. Прогнать через модель dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75d6c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Question: What is the weather like?\\nAnswer: Today is a good day!\\n\"\n",
    "question = \"Question: What is the weather like?\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b1ac932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is a good day!\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "764af776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    original_text, predicted_text, original_answer, predicted_answer = [], [], [], []\n",
    "\n",
    "    bleu_scores = []\n",
    "    rouge_scores = []\n",
    "\n",
    "    for encoded_ids, _, _, answer, question in tqdm(test_dataset):\n",
    "\n",
    "        original_text.append(f\"Question: {question}\\nAnswer: {answer}\")\n",
    "        original_answer.append(f\"Answer: {answer}\")\n",
    "\n",
    "        question_len = len(f\"Question: {question}\\nAnswer: \")\n",
    "\n",
    "        text_to_answer = f\"<|startoftext|>Question: {question}\\nAnswer:\"\n",
    "\n",
    "        enc_text_to_answer = tokenizer(text_to_answer, return_tensors=\"pt\").input_ids\n",
    "\n",
    "        generated_output = model.generate(\n",
    "            enc_text_to_answer,\n",
    "            do_sample=False,\n",
    "            top_k=50,\n",
    "            max_length=max_length,\n",
    "            top_p=0.90,\n",
    "            temperature=0,\n",
    "            num_return_sequences=0,\n",
    "        )\n",
    "        # возвращается с pad\n",
    "        generated_q_a = tokenizer.batch_decode(\n",
    "            generated_output[0], skip_special_rokens=True\n",
    "        )\n",
    "        generated_a = generated_q_a[question_len:]\n",
    "\n",
    "        predicted_text.append(generated_q_a)\n",
    "        predicted_answer.append(generated_a)\n",
    "\n",
    "        bleu_scores.append(\n",
    "            bleu.compute(predictions=generated_a, references=answer)[\"bleu\"]\n",
    "        )\n",
    "        rouge_scores.append(\n",
    "            rouge.compute(predictions=generated_a, references=answer)[\n",
    "                \"rouge1\"\n",
    "            ].mid.fmeasure\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        original_text,\n",
    "        predicted_text,\n",
    "        original_answer,\n",
    "        predicted_answer,\n",
    "        np.mean(bleu_scores),\n",
    "        np.mean(rouge_scores),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76999665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This partly depends on your mod_wsgi configuration. If you configure it to use only one thread per process, then global variables are safe--although I wouldn't recommend using them, for a variety of reasons. In a multi-thread configuration, there is nothing guaranteeing that requests won't get mixed up if you use global variables.\\nYou should be able to find some more local place to stash the data you need between pre_save and post_save. I'd recommend putting some more thought into your design.\\n<|startoftext|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_q_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5c0bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
